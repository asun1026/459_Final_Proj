{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b0d5fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import networkx as nx\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "265681d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FILE = 'Data/node_text_data.json'\n",
    "MAPPING_FILE = 'Data/url_id_mapping.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a421448",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json_file(filename):\n",
    "    \"\"\"Loads data from a JSON file.\"\"\"\n",
    "    if not os.path.exists(filename):\n",
    "        print(f\"Error: File '{filename}' not found.\")\n",
    "        return None\n",
    "    try:\n",
    "        with open(filename, 'r', encoding='utf-8') as f:\n",
    "            return json.load(f)\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error decoding JSON from '{filename}': {e}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while reading '{filename}': {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "901479da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_stackoverflow_urls(text):\n",
    "    \"\"\"Extracts potential Stack Overflow URLs from text using regex.\"\"\"\n",
    "    # Simple regex to find Stack Overflow URLs - adjust as needed\n",
    "    # This looks for stackoverflow.com/questions/ followed by numbers\n",
    "    pattern = r'https?://stackoverflow\\.com/questions/\\d+/[^ \\s\\'\\\"\\)\\]\\}]+'\n",
    "    urls = re.findall(pattern, text)\n",
    "    return urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de5bf5af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Building reverse mapping (ID to URL)...\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading data...\")\n",
    "# Load the data and mapping files\n",
    "node_data = load_json_file(DATA_FILE)\n",
    "url_to_id_mapping = load_json_file(MAPPING_FILE)\n",
    "\n",
    "if node_data is None or url_to_id_mapping is None:\n",
    "    print(\"Failed to load necessary data files. Exiting.\")\n",
    "\n",
    "print(\"Building reverse mapping (ID to URL)...\")\n",
    "# Create a reverse mapping for easier lookup\n",
    "# Need to handle potential missing 'url_to_id' key\n",
    "if 'url_to_id' not in url_to_id_mapping:\n",
    "    print(f\"Error: Key 'url_to_id' not found in {MAPPING_FILE}\")\n",
    "    \n",
    "id_to_url_mapping = {v: k for k, v in url_to_id_mapping['url_to_id'].items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00bfbeae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating graph...\n",
      "Adding nodes...\n",
      "Attempting to add edges based on explicit URLs...\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating graph...\")\n",
    "# Create a directed graph\n",
    "G = nx.DiGraph()\n",
    "\n",
    "print(\"Adding nodes...\")\n",
    "# Add nodes to the graph\n",
    "for node_id, text_content in node_data.items():\n",
    "    # Ensure node_id exists in the reverse mapping\n",
    "    node_url = id_to_url_mapping.get(int(node_id)) # Convert node_id string to int for lookup\n",
    "    if node_url:\n",
    "        G.add_node(\n",
    "            node_id,\n",
    "            url=node_url,\n",
    "            text=text_content\n",
    "            # Add other attributes if needed\n",
    "        )\n",
    "    else:\n",
    "            print(f\"Warning: No URL found for node ID {node_id}. Skipping node.\")\n",
    "\n",
    "\n",
    "print(\"Attempting to add edges based on explicit URLs...\")\n",
    "# Add edges based on URLs found in text content\n",
    "edges_added = 0\n",
    "for source_id, data in G.nodes(data=True):\n",
    "    if 'text' in data:\n",
    "        found_urls = extract_stackoverflow_urls(data['text'])\n",
    "        for url in found_urls:\n",
    "            # Check if the found URL exists in our mapping\n",
    "            target_id_str = url_to_id_mapping['url_to_id'].get(url)\n",
    "            if target_id_str is not None:\n",
    "                # Ensure the target node actually exists in the graph\n",
    "                if G.has_node(target_id_str):\n",
    "                        # Avoid self-loops unless desired\n",
    "                    if source_id != target_id_str:\n",
    "                        G.add_edge(source_id, target_id_str)\n",
    "                        edges_added += 1\n",
    "                else:\n",
    "                        print(f\"Warning: Found URL {url} mapping to ID {target_id_str}, but node not in graph.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0874a0d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Graph Inspection ---\n",
      "Number of nodes: 4168\n",
      "Number of edges found (based on simple URL extraction): 0\n",
      "\n",
      "Sample Node Data:\n",
      "\n",
      "Node ID: 3558\n",
      "  URL: https://stackoverflow.com/documentation/ios/topics\n",
      "  Text Preview: We have shut down Stack Overflow Documentation. Documentation was our attempt at improving existing ...\n",
      "\n",
      "Node ID: 1245\n",
      "  URL: https://stackoverflow.com/?ref=blog.krugazor.eu\n",
      "  Text Preview: Every tab open to Stack Overflow. has aFor over 15 years weâ€™ve been the Q&A platform of choice that ...\n",
      "\n",
      "Node ID: 866\n",
      "  URL: https://stackoverflow.com/help/badges/680\n",
      "  Text Preview: Tags Awarded Mar 15, 2019 at 4:03 to Awarded May 22, 2017 at 4:03 to Awarded Mar 22, 2016 at 4:03 to...\n",
      "\n",
      "Sample Edges:\n",
      "\n",
      "--- Further Analysis Suggestions ---\n",
      "- Improve edge detection using NLP (e.g., linking based on mentioned question titles/IDs).\n",
      "- Analyze node centrality (degree, betweenness, etc.).\n",
      "- Visualize the graph (requires matplotlib or other plotting libraries).\n",
      "- Perform community detection.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Graph Inspection ---\")\n",
    "print(f\"Number of nodes: {G.number_of_nodes()}\")\n",
    "print(f\"Number of edges found (based on simple URL extraction): {G.number_of_edges()}\")\n",
    "\n",
    "# Display info for a few sample nodes\n",
    "print(\"\\nSample Node Data:\")\n",
    "node_list = list(G.nodes())\n",
    "for i in range(min(3, len(node_list))): # Show up to 3 nodes\n",
    "    node_id = node_list[i]\n",
    "    print(f\"\\nNode ID: {node_id}\")\n",
    "    print(f\"  URL: {G.nodes[node_id].get('url', 'N/A')}\")\n",
    "    text_preview = G.nodes[node_id].get('text', '')[:100] # Preview first 100 chars\n",
    "    print(f\"  Text Preview: {text_preview}...\")\n",
    "\n",
    "# Display info for a few sample edges\n",
    "print(\"\\nSample Edges:\")\n",
    "edge_list = list(G.edges())\n",
    "for i in range(min(3, len(edge_list))): # Show up to 3 edges\n",
    "    print(f\"  {edge_list[i][0]} -> {edge_list[i][1]}\")\n",
    "\n",
    "print(\"\\n--- Further Analysis Suggestions ---\")\n",
    "print(\"- Improve edge detection using NLP (e.g., linking based on mentioned question titles/IDs).\")\n",
    "print(\"- Analyze node centrality (degree, betweenness, etc.).\")\n",
    "print(\"- Visualize the graph (requires matplotlib or other plotting libraries).\")\n",
    "print(\"- Perform community detection.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "459_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
